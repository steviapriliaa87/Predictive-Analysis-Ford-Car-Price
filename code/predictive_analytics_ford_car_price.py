# -*- coding: utf-8 -*-
"""PREDICTIVE ANALYTICS - FORD CAR PRICE

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-zQv9ZtERd_lV38htudCPI2EpnL41ZFI

# **PREDICTIVE ANALYTICS - FORD CAR PRICE**
# Oleh : Stevi Aprilianti Cahyani

---

## **1. Data Understanding**

### **Import Library**
"""

# ====== Import Library Dasar ======
import numpy as np
import pandas as pd

# ====== Visualisasi Data ======
import matplotlib.pyplot as plt
import seaborn as sns

# ====== Import dari Google Colab ======
from google.colab import files
import zipfile

# ====== Preprocessing dan Transformasi ======
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.decomposition import PCA

# ====== Model Regresi ======
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor

# ====== Evaluasi dan Split Data ======
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# ====== Deep Learning  ======
import tensorflow as tf

"""### **Data Loading**

Tahap *Data Loading* adalah proses pengambilan dan pembacaan dataset dari sumber eksternal ke dalam notebook Python. Dalam proyek ini, dataset diambil langsung dari Kaggle menggunakan API resmi dari Kaggle. Proses ini memungkinkan kita mengakses dataset tanpa harus mengunggahnya secara manual.

Langkah-langkah yang dilakukan dalam tahap ini antara lain:

1. **Mengatur API Kaggle**
   
   Untuk bisa mengakses dataset, perlu mengatur autentikasi menggunakan file `kaggle.json` yang berisi API key. File ini bisa diunduh dari akun Kaggle, lalu di-*upload* ke Google Colab.


2. **Memindahkan File ke Direktori yang Sesuai**
   
   Setelah `kaggle.json` ter-upload, perlu dipindahkan ke direktori `.kaggle`.


3. **Mengunduh Dataset dari Kaggle**
   
   Menggunakan perintah `kaggle datasets download`.


4. **Ekstraksi File Dataset (Jika Dalam Bentuk Zip)**
  
   Biasanya file yang diunduh berbentuk `.zip`, sehingga perlu diekstrak.


5. **Membaca Dataset dengan Pandas**
  
   Setelah file berhasil diekstrak, file `.csv` dapat dibaca dengan `pandas`.


Tahap ini memungkinkan pengambilan dataset secara otomatis dari Kaggle, yang sangat membantu dalam menghemat waktu dan menghindari proses upload manual.
"""

# Upload kaggle.json
files.upload()  # Upload kaggle.json

# Membuat direktori
!mkdir -p ~/.kaggle
# Menyalin file API `kaggle.json`
!cp kaggle.json ~/.kaggle/
# Mengatur permission file `kaggle.json`
!chmod 600 ~/.kaggle/kaggle.json

# Mengunduh dataset "ford-car-price-prediction" dari Kaggle menggunakan Kaggle API
!kaggle datasets download -d adhurimquku/ford-car-price-prediction

# Membuka file ZIP dari dataset yang telah diunduh
zip_ref = zipfile.ZipFile('/content/ford-car-price-prediction.zip', 'r')
# Mengekstrak seluruh isi file ZIP ke direktori /content/
zip_ref.extractall('/content/')
# Menutup file ZIP setelah proses ekstraksi selesai
zip_ref.close()

# Membaca file CSV
df_FordCar = pd.read_csv('/content/ford.csv')
# Menampilkan isi DataFrame df_FordCar
df_FordCar

"""## **2. Exploratory Data Analysis & Cleaning Data**

###**Cek Tipe Data**
"""

df_FordCar.info()

"""Dataset ini berisi **17.966 data mobil Ford** dengan total **9 kolom informasi**. Setiap baris mewakili satu mobil dengan berbagai detail yaitu

* **Model**: Jenis mobil Ford (misalnya Fiesta, Focus, dll).
* **Year**: Tahun pembuatan mobil.
* **Price**: Harga mobil dalam satuan mata uang tertentu.
* **Transmission**: Tipe transmisi mobil (Manual, Automatic, dll).
* **Mileage**: Jarak tempuh mobil dalam satuan kilometer atau mil.
* **FuelType**: Jenis bahan bakar yang digunakan (Bensin, Diesel, Hybrid, dll).
* **Tax**: Besarnya pajak tahunan kendaraan.
* **MPG (Miles per Gallon)**: Konsumsi bahan bakar, menunjukkan efisiensi penggunaan bensin.
* **Engine Size**: Kapasitas mesin mobil dalam liter.

Terdapat **6 data numerik** yakni: `year`, `price`, `mileage`, `tax`, `mpg`, dan `engineSize`
lalu **3 data kategoris** yakni: `model`, `transmission`, dan `fuelType`.

### **Cek Ringkasan Statistik**
"""

df_FordCar.describe()

"""Dataset ini berisi 17.966 data mobil Ford. Rata-rata tahun mobil adalah 2016, dengan tahun tertua 1996 dan tertinggi tercatat 2060 (kemungkinan data tidak valid). Harga mobil rata-rata sekitar £12.280, dengan harga termurah £495 dan termahal £54.995. Jarak tempuh (mileage) rata-rata adalah 23.362 mil, dengan maksimal hingga 177.644 mil.

Besaran pajak (tax) bervariasi, dengan nilai rata-rata £113 dan maksimal £580. Konsumsi bahan bakar (mpg) rata-rata 57.9 mpg, menunjukkan banyak mobil hemat bahan bakar, namun ada nilai ekstrim hingga 201.8 mpg (kemungkinan error). Ukuran mesin (engineSize) rata-rata 1.35L, dengan rentang dari 0.0L hingga 5.0L, menunjukkan adanya data yang mungkin perlu dibersihkan atau diperiksa lebih lanjut.

### **Cek Missing Value**
"""

df_FordCar.isnull().sum()

"""Berdasarkan output, tidak ditemukan nilai kosong (missing values) pada dataset. Namun, perlu dilakukan pengecekan lebih lanjut terhadap keberadaan nilai 0 pada beberapa kolom numerik. Hal ini penting karena berdasarkan ringkasan statistik, terdapat nilai minimum 0.000000 yang tampak janggal, khususnya pada fitur `engineSize`. Nilai 0 pada fitur ini kemungkinan besar bukan representasi yang valid, mengingat secara logika setiap mobil pasti memiliki kapasitas mesin lebih dari nol.


"""

# Menghitung jumlah baris yang memiliki nilai 0 pada kolom 'engineSize'
engineSize = (df_FordCar.engineSize == 0).sum()
print('Jumlah nilai 0 pada kolom engineSize adalah', engineSize)

# Menampilkan semua baris yang memiliki nilai 0 pada kolom 'engineSize'
df_FordCar.loc[df_FordCar['engineSize'] == 0]

"""Setelah dilakukan pengecekan, ditemukan bahwa terdapat 51 data dengan nilai 0 pada fitur engineSize. Karena nilai 0 tidak masuk akal untuk kapasitas mesin mobil, maka langkah yang tepat selanjutnya adalah menghapus baris-baris data tersebut untuk menjaga kualitas dan validitas analisis"""

# Menghapus semua baris yang memiliki nilai 0 pada kolom 'engineSize'
df_FordCar = df_FordCar.loc[(df_FordCar[['engineSize']] != 0).all(axis=1)]

# cek ulang ringkasan statistik setelah pembersihan
df_FordCar.describe()

# cek kembali jumlah data setelah pembersihan
df_FordCar.shape

"""Setelah menghapus semua baris yang memiliki nilai `engineSize` sama dengan 0, dataset `df_FordCar` kini berisi **17.915 baris** dan **9 kolom**.

Ini berarti ada **51 baris** yang dibuang dari dataset asli yang berjumlah 17.966 baris.

Langkah ini membantu memastikan bahwa data yang digunakan untuk analisis atau pemodelan hanya berisi informasi yang valid terkait ukuran mesin mobil, sehingga hasil analisis menjadi lebih akurat dan terpercaya.

### **Cek Outliers**
"""

plt.subplots(figsize=(10, 7))
sns.boxplot(data=df_FordCar)
plt.title("Boxplot Periksa Outliers Dataset Ford Car")
plt.xticks(rotation=45)

"""Boxplot menunjukkan adanya **outlier** di hampir semua fitur numerik dalam dataset mobil Ford. Outlier paling mencolok terlihat pada kolom **mileage** (jarak tempuh) dan **price** (harga mobil), di mana banyak nilai berada jauh di atas batas atas (upper whisker). Kolom **year** juga menunjukkan beberapa data tahun yang tidak wajar (misalnya tahun 2060), sedangkan **engineSize** memiliki nilai nol yang tampaknya tidak valid. Kolom **tax** dan **mpg** memiliki sedikit outlier, tapi masih dalam batas yang lebih terkendali. Secara keseluruhan, boxplot ini menunjukkan perlunya pembersihan data, terutama pada outlier yang ekstrem dan nilai yang tidak realistis.

**Menangani Outlier**
"""

# Pilih hanya kolom numerik
num_cols = df_FordCar.select_dtypes(include='number').columns

# Hitung Q1, Q3 dan IQR hanya untuk kolom numerik
Q1 = df_FordCar[num_cols].quantile(0.25)
Q3 = df_FordCar[num_cols].quantile(0.75)
IQR = Q3 - Q1

# Filter data yang bukan outlier (hanya berdasarkan kolom numerik)
df_FordCar = df_FordCar[~((df_FordCar[num_cols] < (Q1 - 1.5 * IQR)) | (df_FordCar[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]

print(f"Data berhasil ditangani outliernya. Jumlah data setelah pembersihan: {df_FordCar.shape[0]} baris dan {df_FordCar.shape[1]} kolom.")

plt.subplots(figsize=(10, 7))
sns.boxplot(data=df_FordCar)
plt.title("Boxplot Setelah Pembersihan  Outliers Dataset Ford Car")
plt.xticks(rotation=45)

"""Boxplot menunjukkan bahwa data kini jauh lebih bersih dibanding sebelumnya. Nilai-nilai ekstrem yang sebelumnya mendominasi kolom price, mileage, dan year telah berhasil dikurangi. Distribusi data menjadi lebih seimbang, dan mayoritas nilai berada dalam rentang normal.

### **Univariate Analysis**

Insialisasi/pemisahan (segregasi) variabel berdasarkan tipe data
"""

numerical = ['year','price','mileage','tax','mpg','engineSize']
categorical = ['model','transmission','fuelType']

"""Analisis Fitur Categorical - Model"""

# Mengambil nama fitur kategorikal pertama dari list 'categorical'
feature = categorical[0]
# Menghitung jumlah setiap kategori pada fitur tersebut
count = df_FordCar[feature].value_counts()
# Membuat DataFrame
df_model = pd.DataFrame({
    'jumlah sample': count,
})
# Menampilkan DataFrame ringkasan
print(df_model)

# Visualisasi
plt.figure(figsize=(8, 5))
count.plot(kind='barh', color='lightcoral')
plt.title(f'Jumlah Tiap Kategori pada Fitur "{feature}"')
plt.xlabel('Jumlah Sampel')
plt.ylabel('Kategori')
plt.tight_layout()
plt.show()

"""Analisis fitur categorical - Transmission"""

# Memilih fitur kategorikal kedua dari daftar 'categorical' yaitu transmission
feature = categorical[1]
# Menghitung frekuensi setiap kategori dalam fitur tersebut
count = df_FordCar[feature].value_counts()
# Membuat DataFrame yang berisi jumlah sampel untuk tiap kategori
df_transmission = pd.DataFrame({
    'jumlah sampel': count,
})
# Menampilkan DataFrame tersebut
print(df_transmission)

# Visualisasi
count.plot(kind='bar')
plt.title(f'Jumlah Sampel per Kategori pada Fitur "{feature}"')
plt.xlabel('Kategori')
plt.ylabel('Jumlah Sampel')
plt.show()

"""Analisis fitur categorical - Fuel Type"""

# Memilih fitur kategorikal kedua dari daftar 'categorical' yaitu Fuel Type
feature = categorical[2]
# Menghitung frekuensi setiap kategori dalam fitur tersebut
count = df_FordCar[feature].value_counts()
# Membuat DataFrame yang berisi jumlah sampel untuk tiap kategori
df_fueltype = pd.DataFrame({
    'jumlah sampel': count,
})
# Menampilkan DataFrame tersebut
print(df_fueltype)

# Visualisasi
count.plot(kind='bar')
plt.title(f'Jumlah Sampel per Kategori pada Fitur "{feature}"')
plt.xlabel('Kategori')
plt.ylabel('Jumlah Sampel')
plt.show()

"""Analisis Fitur Numerical - Year, Price, Mileage, Tax, Mpg dan EngineSize."""

# visualisasi
df_FordCar.hist(
    bins=50,
    figsize= (20 , 15),
    edgecolor='black',
    color='#1f77b4'
)

plt.suptitle('Distribusi Fitur Numerikal Ford Car Dataset', fontsize=20, y=1.02)
plt.tight_layout()
plt.show()

"""### **Multivariate Analysis**"""

categorical_features = df_FordCar.select_dtypes(include='object').columns.to_list()
# Visualisasi
for kolom in categorical_features:
    sns.catplot(
        x=kolom,
        y='price',
        kind='bar',
        dodge=False,
        height=8,
        aspect=3,
        data=df_FordCar,
        color='#4C72B0'
    )
    plt.title(f'Rata-rata harga berdasarkan {kolom}')

"""### **Memeriksa Korelasi antara Fitur Numerik dengan Fitur Target menggunakan Fungsi corr()**"""

# Membuat pairplot
pairplot = sns.pairplot(df_FordCar, diag_kind='kde')
pairplot.fig.suptitle("Pairplot Dataset Ford Car", y=1.02, fontsize=16)  # y=1.02 untuk sedikit di atas plot
plt.show()

"""Pairplot digunakan untuk mengeksplorasi hubungan antar fitur numerik dengan cara memvisualisasikan scatter plot untuk setiap pasangan fitur, serta distribusi dari masing-masing fitur di diagonal.


1. **year vs price**
   Terlihat **korelasi positif**: mobil yang lebih baru (tahun lebih tinggi) cenderung memiliki **harga lebih mahal**.

2. **mileage vs price**
   Terdapat **korelasi negatif**: semakin besar mileage (jarak tempuh), **harga mobil menurun**. Ini logis karena mobil dengan jarak tempuh tinggi biasanya lebih murah.

3. **tax dan mpg**

   * Nilai **tax** cenderung bervariasi dalam kelompok (diskrit), terlihat seperti garis horizontal.
   * **mpg (miles per gallon)** memiliki sebaran yang cukup lebar, dan tampak hubungan **negatif terhadap engineSize**, di mana mobil dengan mesin lebih besar cenderung memiliki efisiensi bahan bakar yang lebih rendah.

4. **engineSize vs price**
   Cenderung **korelasi positif**: mobil dengan mesin lebih besar biasanya lebih mahal.

5. **Distribusi** (diagonal)

   * Fitur seperti `year`, `tax`, `engineSize` bersifat **diskrit** (nilai-nilai terbatas).
   * `price` dan `mileage` memiliki distribusi **right-skewed**, banyak data di harga/jarak rendah dan sedikit di harga/jarak tinggi.

6. **Hubungan antar fitur lainnya**

   * `year` dan `mileage` menunjukkan **korelasi negatif**, mobil yang lebih baru cenderung memiliki mileage yang lebih rendah.
   * Korelasi antara `mpg` dan `engineSize` juga terlihat cukup kuat secara visual: makin besar mesin, makin boros bahan bakar.

### **Memeriksa Kolerasi Fitur Numerik Menggunakan Heatmap**
"""

plt.figure(figsize=(10,8))

# Ambil hanya kolom numerik
num_cols = df_FordCar.select_dtypes(include='number')

# Hitung korelasi
corre_matrix = num_cols.corr().round(2)

# Visualisasi heatmap
sns.heatmap(data=corre_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Matriks Korelasi Fitur Numerik', size=20)
plt.show()

"""Heatmap digunakan untuk menunjukkan **hubungan linear antar fitur numerik** dalam bentuk **koefisien korelasi Pearson**:


1. **Korelasi Positif Tinggi**

   * `year` dengan `price` (**0.64**): Mobil yang lebih baru cenderung lebih mahal.
   * `tax` dengan `price` (**0.49**) dan `year` (\*\*0.52\`): Pajak kendaraan cenderung lebih tinggi untuk mobil yang baru dan mahal.
   * `engineSize` dengan `price` (**0.40**): Mesin lebih besar umumnya terdapat pada mobil yang lebih mahal.

2. **Korelasi Negatif Kuat**

   * `mileage` dengan `year` (**-0.67**) dan `price` (**-0.48**): Mobil yang lebih tua cenderung memiliki jarak tempuh lebih tinggi dan harga yang lebih rendah.
   * `mpg` dengan `tax` (**-0.48**): Semakin irit mobil (mpg tinggi), biasanya semakin rendah pajaknya.

3. **Korelasi Lemah atau Hampir Tidak Ada**

   * `engineSize` memiliki korelasi rendah terhadap sebagian besar fitur lainnya kecuali `price`.
   * `mpg` punya korelasi kecil negatif terhadap `year` dan `engineSize`.


"""

# drop beberapa fitur karena korelasinya rendah
df_FordCar.drop(['mileage'], inplace=True, axis=1)
df_FordCar.drop(['mpg'], inplace=True, axis=1)
df_FordCar

"""## **3. Data Preparation**

### Encoding Fitur Category
"""

# Encoding kolom 'model'
model_dummies = pd.get_dummies(df_FordCar['model'], prefix='model', drop_first=True)

# Encoding kolom 'transmission'
transmission_dummies = pd.get_dummies(df_FordCar['transmission'], prefix='transmission', drop_first=True)

# Encoding kolom 'fuelType'
fuel_dummies = pd.get_dummies(df_FordCar['fuelType'], prefix='fuelType', drop_first=True)

# Menggabungkan hasil encoding ke DataFrame utama
df_FordCar = pd.concat([df_FordCar, model_dummies, transmission_dummies, fuel_dummies], axis=1)

# Hapus kolom aslinya karena sudah diencoding
df_FordCar.drop(['model', 'transmission', 'fuelType'], axis=1, inplace=True)

# Tampilkan hasil
print("Hasil Encoding:")
df_FordCar.head()

"""### Reduksi Dimensi PCA"""

sns.pairplot(df_FordCar[['engineSize','tax']], plot_kws={'s':2})

"""**Aplikasi Class PCA**"""

# Inisialisasi PCA (Principal Component Analysis) untuk mereduksi dimensi menjadi 2 komponen utama
pca = PCA(n_components=2, random_state=69)

# Melatih (fit) PCA pada dua fitur: 'engineSize' dan 'tax'
# PCA akan mencari kombinasi linier terbaik dari kedua fitur ini
pca.fit(df_FordCar[['engineSize','tax']])

# Mentransformasikan data asli menjadi dua principal components (komponen utama)
# Hasilnya adalah representasi baru dari data dalam ruang berdimensi 2
princ_comp = pca.transform(df_FordCar[['engineSize','tax']])

"""**Informasi Kedua Komponen**"""

# Menampilkan rasio variansi yang dijelaskan oleh masing-masing komponen utama dari PCA
# Ini menunjukkan seberapa besar informasi (variansi) dari data asli yang berhasil ditangkap oleh masing-masing komponen
pca.explained_variance_ratio_.round(2)

"""### Membuat Fitur dengan nama 'feature'"""

# Inisialisasi PCA untuk mereduksi dua fitur ('engineSize' dan 'tax') menjadi satu komponen utama
pca = PCA(n_components=1, random_state=69)

# Melatih model PCA pada fitur 'engineSize' dan 'tax'
pca.fit(df_FordCar[['engineSize', 'tax']])

# Mentransformasikan dua fitur tersebut menjadi satu fitur baru hasil PCA, lalu flatten agar menjadi 1D array
df_FordCar['feature'] = pca.transform(df_FordCar[['engineSize', 'tax']]).flatten()

# Menghapus kolom asli 'engineSize' dan 'tax' karena sudah direpresentasikan dalam fitur baru
df_FordCar.drop(['engineSize', 'tax'], axis=1, inplace=True)

"""### Membagi Data Latih & Data Uji dengan Train Test Split"""

# Memisahkan fitur (X) dan target (y)
x = df_FordCar.drop(['price'], axis=1)   # X = semua kolom kecuali 'price'
y = df_FordCar['price']                  # y = kolom 'price' sebagai target

# Membagi data menjadi data latih dan data uji (80% latih, 20% uji)
x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state=69
)

# Menampilkan ukuran masing-masing data
print("Ukuran x_train dan y_train:", x_train.shape, y_train.shape)
print("Ukuran x_test dan y_test:", x_test.shape, y_test.shape)

"""### Standarisasi"""

# Menentukan kolom numerik yang akan dinormalisasi
numerical = ['year', 'feature']

# Inisialisasi StandardScaler
scaler = StandardScaler()

# Melatih scaler hanya pada data latih
scaler.fit(x_train[numerical])

# Transformasi kolom numerik di data latih agar terstandarisasi (mean = 0, std = 1)
x_train[numerical] = scaler.transform(x_train[numerical])

# Menampilkan 5 baris pertama dari kolom numerik yang sudah dinormalisasi
x_train[numerical].head()

# Menampilkan ringkasan statistik dari kolom numerik yang sudah dinormalisasi
# Hasilnya dibulatkan hingga 4 angka di belakang koma
x_train[numerical].describe().round(4)

"""## **4. Model Development**

### Menyiapkan Dataframe
"""

# Membuat DataFrame kosong untuk menyimpan nilai MSE (Mean Squared Error)
# dari masing-masing model pada data train dan test
models = pd.DataFrame(
    index=['train_mse', 'test_mse'],
    columns=['KNN', 'RandomForest', 'Boosting']
)

"""### K-Nearest Neighbor"""

# Inisialisasi model K-Nearest Neighbors Regressor dengan 10 tetangga terdekat
KNN_model = KNeighborsRegressor(n_neighbors=10)

# Melatih model KNN dengan data pelatihan
KNN_model.fit(x_train, y_train)

# Memprediksi harga mobil pada data pelatihan menggunakan model yang sudah dilatih
y_pred_KNN_model = KNN_model.predict(x_train)

"""### Random Forest"""

# Inisialisasi model Random Forest Regressor
RF_model = RandomForestRegressor(
    n_estimators=45,
    max_depth=16,
    random_state=69,
    n_jobs=-1
)

# Melatih model dengan data pelatihan
RF_model.fit(x_train, y_train)

# Menghitung Mean Squared Error (MSE) pada data pelatihan dan simpan ke dalam tabel `models`
models.loc['train_mse', 'RandomForest'] = mean_squared_error(
    y_pred=RF_model.predict(x_train),
    y_true=y_train
)

"""### Boosting Algorithm"""

# Inisialisasi model AdaBoost Regressor
BA_model = AdaBoostRegressor(
    n_estimators=50,
    learning_rate=0.05,
    random_state=69
)

# Melatih model dengan data pelatihan
BA_model.fit(x_train, y_train)

# Menghitung Mean Squared Error (MSE) pada data pelatihan dan simpan ke dalam tabel `models`
models.loc['train_mse', 'Boosting'] = mean_squared_error(
    y_pred=BA_model.predict(x_train),
    y_true=y_train
)

"""## **5. Evaluasi Model**

### **Mengukur nilai error dengan MSE**
"""

# Transformasi fitur numerik pada data testing menggunakan scaler yang sudah fit di data training
x_test.loc[:, numerical] = scaler.transform(x_test[numerical])

# Membuat DataFrame untuk menyimpan nilai MSE (Mean Squared Error) pada data train dan test
MSE = pd.DataFrame(columns=['train', 'test'], index=['KNN', 'RF', 'Boosting'])

# Kamus model untuk memudahkan iterasi
model_dict = {
    'KNN': KNN_model,
    'RF': RF_model,
    'Boosting': BA_model
}

# Looping setiap model untuk hitung MSE pada data train dan test, hasil dibagi 1000 agar lebih mudah dibaca
for name, model in model_dict.items():
    MSE.loc[name, 'train'] = mean_squared_error(
        y_true=y_train,
        y_pred=model.predict(x_train)
    ) / 1e3  # Membagi dengan 1000 supaya skala lebih kecil

    MSE.loc[name, 'test'] = mean_squared_error(
        y_true=y_test,
        y_pred=model.predict(x_test)
    ) / 1e3

# Tampilkan DataFrame hasil evaluasi
MSE

"""### **1. KNN (K-Nearest Neighbors)**

* **Train MSE**: 1703.97
* **Test MSE**: 1887.41
* Artinya:

  * KNN cukup baik dalam mempelajari data latih.
  * Performa di data uji (test) tidak jauh berbeda dari train → **tidak overfitting**, tapi error masih relatif sedang.

---

### **2. RF (Random Forest)**

* **Train MSE**: 1435.29
* **Test MSE**: 1628.64
* Artinya:

  * RF adalah **model terbaik di antara ketiganya**.
  * Error-nya paling kecil pada kedua data.
  * Menunjukkan **generalisasi yang bagus** dan belajar cukup baik dan memprediksi test data dengan akurat.

---

### **3. Boosting (Kemungkinan Gradient Boosting)**

* **Train MSE**: 6429.72
* **Test MSE**: 6579.25
* Artinya:

  * Boosting justru menunjukkan performa yang buruk.
  * MSE sangat besar di train dan test → kemungkinan:

    * Model **underfitting** (tidak cukup belajar dari data).
    * Atau parameter (learning rate, estimators) belum optimal.
    * Atau data memang tidak cocok untuk Boosting.

---

##  **Kesimpulan**

1. **Random Forest** memberikan performa terbaik secara keseluruhan.
2. **KNN** masih masuk akal, tapi akurasinya di bawah RF.
3. **Boosting** memiliki performa jauh lebih buruk dari dua model lain.

### Visualisasi perbandingan hasil performa model pada data test dan train
"""

fig, ax = plt.subplots()

# Plot MSE hasil pengujian model, diurutkan dari yang tertinggi ke terendah berdasarkan nilai MSE test
MSE.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)

# Menambahkan grid di belakang grafik untuk memudahkan pembacaan
ax.grid(zorder=0)

"""### Cek evaluasi performa model"""

KNN_model_accuracy = KNN_model.score(x_test, y_test)*100
RF_model_accuracy = RF_model.score(x_test, y_test)*100
BA_model_accuracy = BA_model.score(x_test, y_test)*100

list_evaluasi = [[KNN_model_accuracy],
            [RF_model_accuracy],
            [BA_model_accuracy]]
eval_model = pd.DataFrame(list_evaluasi,
                        columns=['Accuracy (%)'],
                        index=['K-Nearest Neighbor', 'Random Forest', 'Boosting Algorithm'])
eval_model

"""Berdasarkan hasil output dapat diketahu bahwa :

### **1. Random Forest**

* **Akurasi tertinggi**: 89.73%
* Menunjukkan bahwa model ini paling **akurat dalam memprediksi label data uji**.
* Konsisten dengan hasil MSE sebelumnya, sehingga bisa dikatakan memiliki performa terbaik.

---

### **2. K-Nearest Neighbor (KNN)**

* Akurasi cukup tinggi: **88.09%**
* Hanya sedikit di bawah RF, sehingga bisa dikatakan performa **masih bagus** dan bisa jadi pilihan alternatif.

---

### **3. Boosting Algorithm**

* Akurasi rendah: **58.50%**
* Ini menunjukkan performa yang **buruk dalam klasifikasi**.

---

## **Kesimpulan**

* **Random Forest** adalah model paling baik untuk kasus ini karena memiliki akurasi yang tinggi & MSE rendah.
* **KNN** juga cukup baik dan bisa dipertimbangkan.
* **Boosting Algorithm** memerlukan evaluasi ulang karena menujukkan hasil paling kurang diantara model yang lain.

### Prediksi Model
"""

prediksi = x_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

print(" hasil prediksi :")
print(pd.DataFrame(pred_dict))

"""Pada prediksi satu data uji yang ditampilkan, nilai aktual (y\_true) adalah 9998, sementara hasil prediksi dari ketiga model cukup mendekati namun tetap menunjukkan adanya perbedaan. Model KNN memprediksi 9873.8, Random Forest 9903.7, dan Boosting menghasilkan prediksi sebesar 11707.4. Dari ketiganya, Random Forest memberikan hasil paling mendekati nilai aktual, diikuti oleh KNN, sedangkan Boosting memberikan prediksi yang paling meleset. Hal ini menunjukkan bahwa meskipun Boosting umumnya digunakan untuk meningkatkan akurasi, dalam kasus ini performanya justru buruk, sejalan dengan hasil evaluasi sebelumnya yang menunjukkan akurasi terendah. Sementara KNN dan Random Forest tetap menunjukkan performa prediktif yang baik dan stabil, dengan kesalahan relatif kecil terhadap nilai sebenarnya.

"""